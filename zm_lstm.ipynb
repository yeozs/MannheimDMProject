{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and constants\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from lstm_preprocessing import lstm_preprocessing\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42) \n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(os.getcwd() + '\\\\airlines_reviews.csv')\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "tokenized_dataset = zs_preprocessing(dataset=raw_dataset.sample(1000, ignore_index=True)) ##TODO: Remove sampling\n",
    "tokenized_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset class\n",
    "    ## Uses preprocessing method above\n",
    "    ## __getitem__ returns (preprocessed) text and its corresponding label\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, reviews, labels):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple of a preprocessed review and the corresponding label. If the\n",
    "        vocabulary is enabled, returns a numerical representation of the review.\n",
    "\n",
    "        Args:\n",
    "            idx: a single index\n",
    "        Returns: a (review, label) tuple\n",
    "        \"\"\"\n",
    "        ret_review = self.reviews[idx]\n",
    "        ret_label = self.labels[idx]\n",
    "        \n",
    "        return ret_review, ret_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the Dataset class\n",
    "temp_dataset = tokenized_dataset[:10]\n",
    "test_dataset = ReviewsDataset(reviews=temp_dataset['Tokenized_Reviews'], labels=temp_dataset['Sentiment'])\n",
    "review, label = test_dataset.__getitem__(3)\n",
    "print(review)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split dataset\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    tokenized_dataset, [0.8, 0.1, 0.1], generator=torch.Generator()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM model\n",
    "    ## Embedding layer\n",
    "    ## LSTM (for thought vector)\n",
    "    ## Linear layer (for logit score)\n",
    "    ## Activation (for P of +ve sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training function / Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning\n",
    "    ## Dropout probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_mining_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
